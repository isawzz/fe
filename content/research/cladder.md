---
title: CLadder
raw_date: Fall 2023
repo: causalNLP/cladder
# arxiv: 
# cover: https://images.unsplash.com/photo-1518810765707-4f7d5d811ce0?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1440&q=80
cover: https://images.unsplash.com/photo-1572814895138-9a1501883636?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1440&q=80
# emoji: ü§π
emoji: ü™ú
description: A benchmark for formal causal reasoning in Large Language Models 
---

> [CLadder: Assessing Causal Reasoning in Language Models](https://openreview.net/forum?id=hdZeYGNCTtN)
> 
> **Zhijing Jin**, **Yuen Chen**, **Felix Leeb**, **Luigi Gresele**, Ojasv Kamal, Zhiheng LYU, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, Bernhard Sch√∂lkopf

Recent developments in large language models (LLMs) have led to a surge of interest in the capabilities of these models. However, it is still unclear how well these models can perform causal reasoning, a key aspect of intelligence. Here, I worked with several colleagues to develop a benchmark to study the novel task of "causal inference in natural language."

My contribution included designing and developing the dataset generation including simulating causal models and a rich verbalization of the questions, answers, and step-by-step solutions.

We will present our work at the [NeurIPS 2023](https://openreview.net/forum?id=e2wtjx0Yqu) main conference.

